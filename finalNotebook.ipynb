{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Submission notebook\n",
    "### Author Robert Allan\n",
    "#### Student number 20905488"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Paths: csv text data (train.csv and test.csv) are unzipped into the same directory as the notebook. Likewise the images are unzipped into the .\\suffled-images\\shuffled-images\\ path (as per the zip file). The notebook was run on a windows anaconda installation with a 1660ti (6 Gb VRAM) and 32Gb ram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "import scipy\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv ('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "      <th>gender</th>\n",
       "      <th>baseColour</th>\n",
       "      <th>season</th>\n",
       "      <th>usage</th>\n",
       "      <th>noisyTextDescription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36274</td>\n",
       "      <td>Scarves</td>\n",
       "      <td>Women</td>\n",
       "      <td>Grey</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Femella Women Ankle-Length Grey AQ-S800WD-1EVD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15129</td>\n",
       "      <td>Flip Flops</td>\n",
       "      <td>Unisex</td>\n",
       "      <td>Green</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Converse Unisex Casual Skirts Slipper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58976</td>\n",
       "      <td>Topwear</td>\n",
       "      <td>Women</td>\n",
       "      <td>Red</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Ethnic</td>\n",
       "      <td>Velia Women Acetone Kurta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32922</td>\n",
       "      <td>Sandal</td>\n",
       "      <td>Men</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Enroute Men Leather Brown Sandals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29561</td>\n",
       "      <td>Topwear</td>\n",
       "      <td>Women</td>\n",
       "      <td>Pink</td>\n",
       "      <td>Fall</td>\n",
       "      <td>Ethnic</td>\n",
       "      <td>Aneri Exclusive Anu Pink Inspirartion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    category  gender baseColour  season   usage  \\\n",
       "0  36274     Scarves   Women       Grey  Summer  Casual   \n",
       "1  15129  Flip Flops  Unisex      Green  Summer  Casual   \n",
       "2  58976     Topwear   Women        Red  Summer  Ethnic   \n",
       "3  32922      Sandal     Men      Brown  Summer  Casual   \n",
       "4  29561     Topwear   Women       Pink    Fall  Ethnic   \n",
       "\n",
       "                                noisyTextDescription  \n",
       "0  Femella Women Ankle-Length Grey AQ-S800WD-1EVD...  \n",
       "1              Converse Unisex Casual Skirts Slipper  \n",
       "2                          Velia Women Acetone Kurta  \n",
       "3                  Enroute Men Leather Brown Sandals  \n",
       "4              Aneri Exclusive Anu Pink Inspirartion  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\aetiu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Cleaning\n",
    "Import text from noisy text description and clean and tokenize. First we turn everything to lower case, remove punctuation and digits and stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df['noisyTextDescription']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    \"\"\"Process text function.\n",
    "    Input:\n",
    "        text: a string containing a text\n",
    "    Output:\n",
    "        text_clean: a list of words containing the processed text\n",
    " \n",
    "    \"\"\"\n",
    "    # turn it to lower case\n",
    "    text = text.lower()\n",
    "     \n",
    "    # replace apostrophe with space\n",
    "    text = re.sub('\\'', ' ', text)\n",
    "     \n",
    "    # remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "     \n",
    "    # remove digits\n",
    "    text = re.sub('\\d', '', text)\n",
    "     \n",
    "    stopwords_english = stopwords.words('english')\n",
    " \n",
    " \n",
    "    text_clean = \"\"\n",
    "    text = text.split(' ')\n",
    "    for word in text:\n",
    "        if (word not in stopwords_english):  # remove punctuation\n",
    "            # text_clean.append(word)\n",
    "            text_clean = text_clean +\" \"+word\n",
    "     \n",
    "    # remove double spaces\n",
    "    text_clean = re.sub(' +', ' ', text_clean)\n",
    "    # strip text\n",
    "    text_clean = text_clean.strip()\n",
    " \n",
    "    return text_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = df['noisyTextDescription'].apply(lambda x: process_text(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    femella women anklelength grey aqswdevdfad\n",
       "1         converse unisex casual skirts slipper\n",
       "2                     velia women acetone kurta\n",
       "3             enroute men leather brown sandals\n",
       "4         aneri exclusive anu pink inspirartion\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode labels as one hot encoded vectors (as we're using a neural network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"category\"]\n",
    "\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "enc.fit(np.array(y).reshape(-1, 1))\n",
    "\n",
    "enc.categories_\n",
    "y_oneHot = enc.transform(np.array(y).reshape(-1, 1)).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_oneHot.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn text into TF IDF Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF IDF vectorization top 1000 terms only to save on resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['clean_text']\n",
    "def createTFIDF(arrayClean) :\n",
    "    tf_idf_vec = TfidfVectorizer(use_idf=True, \n",
    "                            smooth_idf=False,  max_features=1000,\n",
    "#                               smooth_idf=False,  max_features=2000,\n",
    "                            ngram_range=(1,1),stop_words='english') # to use only  bigrams ngram_range=(2,2)\n",
    "    #fit\n",
    "    tf_idf_vec = tf_idf_vec.fit(arrayClean)\n",
    "    #transform\n",
    "    tf_idf_data = tf_idf_vec.transform(arrayClean)\n",
    "\n",
    "    #create dataframe\n",
    "    tf_idf_dataframe=pd.DataFrame(tf_idf_data.toarray(),columns=tf_idf_vec.get_feature_names())\n",
    "    return tf_idf_dataframe.values , tf_idf_vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_dataframe, fittedTFIDFVectorizer  = createTFIDF(df['clean_text'])\n",
    "\n",
    "#tf_idf_data =  fittedTFIDFVectorizer.transform(arrayClean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21627, 1000)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name(k):\n",
    "    return 'model_'+str(k)+'.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "yenc = enc.fit(np.array(df['category']).reshape(-1, 1))\n",
    "y_onehot = yenc.transform(np.array(df['category']).reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21627, 27)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_oneHot = enc.transform(np.array(df[\"gender\"]).reshape(-1, 1)).toarray()\n",
    "baseCol_oneHot = enc.transform(np.array(df[\"baseColour\"]).reshape(-1, 1)).toarray()\n",
    "season_oneHot = enc.transform(np.array(df[\"season\"]).reshape(-1, 1)).toarray()\n",
    "usage_oneHot = enc.transform(np.array(df[\"usage\"]).reshape(-1, 1)).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG and image processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import images and associate with observation (via the id column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_paths = []\n",
    "\n",
    "for ident in df['id']:\n",
    "    img_path=glob.glob('.\\\\suffled-images/*/{}.jpg'.format(ident))[0]\n",
    "    train_images_paths.append(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.\\\\suffled-images\\\\shuffled-images\\\\15129.jpg',\n",
       " '.\\\\suffled-images\\\\shuffled-images\\\\58976.jpg']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images_paths[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readImage(file):\n",
    "    img = tf.io.read_file(file)\n",
    "    return (tf.image.decode_jpeg(img, channels=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetImageDS(df):\n",
    "    train_images_paths = []\n",
    "\n",
    "    for ident in df['id']:\n",
    "        img_path=glob.glob('.\\\\suffled-images/*/{}.jpg'.format(ident))[0]\n",
    "        train_images_paths.append(img_path)\n",
    "        data = []\n",
    "#     print(\"finish first for loop\")\n",
    "    j = 0\n",
    "    for i in train_images_paths:   \n",
    "#         if (j%50) == 0:\n",
    "#             print (j)\n",
    "        image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n",
    "    #     target_size= (224,224))\n",
    "        target_size= (60,60))                                                \n",
    "        image=np.array(image)\n",
    "        data.append(image)\n",
    "        \n",
    "        j +=1\n",
    "    arrayImageX = np.array(data)\n",
    "    return arrayImageX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imageX = GetImageDS(df)\n",
    "y_image = df['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           Scarves\n",
       "1        Flip Flops\n",
       "2           Topwear\n",
       "3            Sandal\n",
       "4           Topwear\n",
       "            ...    \n",
       "21622     Innerwear\n",
       "21623         Belts\n",
       "21624         Shoes\n",
       "21625       Watches\n",
       "21626       Topwear\n",
       "Name: category, Length: 21627, dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21627, 1000)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final model is 2 combined neural networks one image processing based using a VGG16 which is initialised from imagenet weights and also one for the text and categorical features, a simple 1024 wide 1 deep neural network to process the TF IDF information as well as one hot encoded categorical data from the others. After this the output of the VGG and text neural network is combined and passed through another 256 wide 1 deep neural network (dense type) and then predicts the final categories (as a vector) using softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "  1/693 [..............................] - ETA: 0s - loss: 15.5709 - accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0171s vs `on_train_batch_end` time: 0.0281s). Check your callbacks.\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.8190 - accuracy: 0.7950\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.89413, saving model to VGGModelX3_model_1.h5\n",
      "693/693 [==============================] - 35s 51ms/step - loss: 0.8190 - accuracy: 0.7950 - val_loss: 0.3972 - val_accuracy: 0.8941\n",
      "Epoch 2/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.3002 - accuracy: 0.9160\n",
      "Epoch 00002: val_accuracy improved from 0.89413 to 0.93504, saving model to VGGModelX3_model_1.h5\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.3002 - accuracy: 0.9160 - val_loss: 0.2466 - val_accuracy: 0.9350\n",
      "Epoch 3/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.1824 - accuracy: 0.9491\n",
      "Epoch 00003: val_accuracy improved from 0.93504 to 0.94475, saving model to VGGModelX3_model_1.h5\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.1824 - accuracy: 0.9491 - val_loss: 0.1992 - val_accuracy: 0.9448\n",
      "Epoch 4/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.1240 - accuracy: 0.9639\n",
      "Epoch 00004: val_accuracy did not improve from 0.94475\n",
      "693/693 [==============================] - 34s 49ms/step - loss: 0.1240 - accuracy: 0.9639 - val_loss: 0.2070 - val_accuracy: 0.9424\n",
      "Epoch 5/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0848 - accuracy: 0.9758 ETA: 1s - l\n",
      "Epoch 00005: val_accuracy improved from 0.94475 to 0.95446, saving model to VGGModelX3_model_1.h5\n",
      "693/693 [==============================] - 34s 50ms/step - loss: 0.0848 - accuracy: 0.9758 - val_loss: 0.1720 - val_accuracy: 0.9545\n",
      "Epoch 6/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0621 - accuracy: 0.9822\n",
      "Epoch 00006: val_accuracy improved from 0.95446 to 0.95885, saving model to VGGModelX3_model_1.h5\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0621 - accuracy: 0.9822 - val_loss: 0.1800 - val_accuracy: 0.9589\n",
      "Epoch 7/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0524 - accuracy: 0.9851\n",
      "Epoch 00007: val_accuracy did not improve from 0.95885\n",
      "693/693 [==============================] - 34s 49ms/step - loss: 0.0524 - accuracy: 0.9851 - val_loss: 0.1727 - val_accuracy: 0.9565\n",
      "Epoch 8/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0387 - accuracy: 0.9879 ETA: 0s - loss: 0.0386 - accura\n",
      "Epoch 00008: val_accuracy improved from 0.95885 to 0.96301, saving model to VGGModelX3_model_1.h5\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0387 - accuracy: 0.9879 - val_loss: 0.1404 - val_accuracy: 0.9630\n",
      "Epoch 9/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0390 - accuracy: 0.9882 ETA: 1s - loss: 0.0\n",
      "Epoch 00009: val_accuracy improved from 0.96301 to 0.96486, saving model to VGGModelX3_model_1.h5\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0390 - accuracy: 0.9882 - val_loss: 0.1646 - val_accuracy: 0.9649\n",
      "Epoch 10/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0250 - accuracy: 0.9931\n",
      "Epoch 00010: val_accuracy improved from 0.96486 to 0.96556, saving model to VGGModelX3_model_1.h5\n",
      "693/693 [==============================] - 35s 51ms/step - loss: 0.0250 - accuracy: 0.9931 - val_loss: 0.1551 - val_accuracy: 0.9656\n",
      "Epoch 11/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0334 - accuracy: 0.9912\n",
      "Epoch 00011: val_accuracy did not improve from 0.96556\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0334 - accuracy: 0.9912 - val_loss: 0.1723 - val_accuracy: 0.9635\n",
      "Epoch 12/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0270 - accuracy: 0.9922\n",
      "Epoch 00012: val_accuracy improved from 0.96556 to 0.96856, saving model to VGGModelX3_model_1.h5\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0270 - accuracy: 0.9922 - val_loss: 0.1405 - val_accuracy: 0.9686\n",
      "Epoch 13/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0154 - accuracy: 0.9958\n",
      "Epoch 00013: val_accuracy did not improve from 0.96856\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0154 - accuracy: 0.9958 - val_loss: 0.1749 - val_accuracy: 0.9644\n",
      "Epoch 14/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0251 - accuracy: 0.9935\n",
      "Epoch 00014: val_accuracy improved from 0.96856 to 0.96949, saving model to VGGModelX3_model_1.h5\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0251 - accuracy: 0.9935 - val_loss: 0.1469 - val_accuracy: 0.9695\n",
      "Epoch 15/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 0.9970\n",
      "Epoch 00015: val_accuracy did not improve from 0.96949\n",
      "693/693 [==============================] - 34s 49ms/step - loss: 0.0121 - accuracy: 0.9970 - val_loss: 0.1673 - val_accuracy: 0.9639\n",
      "Epoch 16/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 0.9923\n",
      "Epoch 00016: val_accuracy did not improve from 0.96949\n",
      "693/693 [==============================] - 34s 49ms/step - loss: 0.0257 - accuracy: 0.9923 - val_loss: 0.1539 - val_accuracy: 0.9690\n",
      "Epoch 17/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9988 ETA - ETA: 1s\n",
      "Epoch 00017: val_accuracy did not improve from 0.96949\n",
      "693/693 [==============================] - 34s 49ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.1655 - val_accuracy: 0.9686\n",
      "Epoch 18/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0083 - accuracy: 0.9979\n",
      "Epoch 00018: val_accuracy improved from 0.96949 to 0.97596, saving model to VGGModelX3_model_1.h5\n",
      "693/693 [==============================] - 34s 50ms/step - loss: 0.0083 - accuracy: 0.9979 - val_loss: 0.1244 - val_accuracy: 0.9760\n",
      "Epoch 19/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0149 - accuracy: 0.9958\n",
      "Epoch 00019: val_accuracy did not improve from 0.97596\n",
      "693/693 [==============================] - 34s 49ms/step - loss: 0.0149 - accuracy: 0.9958 - val_loss: 0.1830 - val_accuracy: 0.9614\n",
      "Epoch 20/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 0.9964\n",
      "Epoch 00020: val_accuracy did not improve from 0.97596\n",
      "693/693 [==============================] - 34s 49ms/step - loss: 0.0138 - accuracy: 0.9964 - val_loss: 0.1876 - val_accuracy: 0.9681\n",
      "Epoch 21/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0151 - accuracy: 0.9962\n",
      "Epoch 00021: val_accuracy did not improve from 0.97596\n",
      "693/693 [==============================] - 34s 49ms/step - loss: 0.0151 - accuracy: 0.9962 - val_loss: 0.1473 - val_accuracy: 0.9713\n",
      "Epoch 22/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9990 ETA: \n",
      "Epoch 00022: val_accuracy did not improve from 0.97596\n",
      "693/693 [==============================] - 34s 49ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.1707 - val_accuracy: 0.9727\n",
      "Epoch 23/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 0.9973\n",
      "Epoch 00023: val_accuracy did not improve from 0.97596\n",
      "693/693 [==============================] - 37s 53ms/step - loss: 0.0099 - accuracy: 0.9973 - val_loss: 0.1598 - val_accuracy: 0.9704\n",
      "Epoch 24/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.9978\n",
      "Epoch 00024: val_accuracy did not improve from 0.97596\n",
      "693/693 [==============================] - 34s 50ms/step - loss: 0.0084 - accuracy: 0.9978 - val_loss: 0.1280 - val_accuracy: 0.9755\n",
      "Epoch 1/50\n",
      "  1/693 [..............................] - ETA: 0s - loss: 15.1699 - accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0166s vs `on_train_batch_end` time: 0.0286s). Check your callbacks.\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.7446 - accuracy: 0.8134\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.88326, saving model to VGGModelX3_model_2.h5\n",
      "693/693 [==============================] - 35s 51ms/step - loss: 0.7446 - accuracy: 0.8134 - val_loss: 0.3969 - val_accuracy: 0.8833\n",
      "Epoch 2/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.2968 - accuracy: 0.9158 ETA: 1s - loss: 0.2973 - accuracy: 0.91 - ETA: 1s -\n",
      "Epoch 00002: val_accuracy improved from 0.88326 to 0.92765, saving model to VGGModelX3_model_2.h5\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.2968 - accuracy: 0.9158 - val_loss: 0.2800 - val_accuracy: 0.9276\n",
      "Epoch 3/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.1837 - accuracy: 0.9461\n",
      "Epoch 00003: val_accuracy improved from 0.92765 to 0.93458, saving model to VGGModelX3_model_2.h5\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.1837 - accuracy: 0.9461 - val_loss: 0.2546 - val_accuracy: 0.9346\n",
      "Epoch 4/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.1138 - accuracy: 0.9677\n",
      "Epoch 00004: val_accuracy improved from 0.93458 to 0.94152, saving model to VGGModelX3_model_2.h5\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.1138 - accuracy: 0.9677 - val_loss: 0.2217 - val_accuracy: 0.9415\n",
      "Epoch 5/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0834 - accuracy: 0.9769\n",
      "Epoch 00005: val_accuracy improved from 0.94152 to 0.94475, saving model to VGGModelX3_model_2.h5\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0834 - accuracy: 0.9769 - val_loss: 0.2104 - val_accuracy: 0.9448\n",
      "Epoch 6/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0624 - accuracy: 0.9813 ETA: 0s - loss: 0.0623 - accuracy: \n",
      "Epoch 00006: val_accuracy improved from 0.94475 to 0.94845, saving model to VGGModelX3_model_2.h5\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0624 - accuracy: 0.9813 - val_loss: 0.1926 - val_accuracy: 0.9485\n",
      "Epoch 7/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0471 - accuracy: 0.9871\n",
      "Epoch 00007: val_accuracy improved from 0.94845 to 0.94961, saving model to VGGModelX3_model_2.h5\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0471 - accuracy: 0.9871 - val_loss: 0.1823 - val_accuracy: 0.9496\n",
      "Epoch 8/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0410 - accuracy: 0.9887\n",
      "Epoch 00008: val_accuracy did not improve from 0.94961\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0410 - accuracy: 0.9887 - val_loss: 0.2101 - val_accuracy: 0.9464\n",
      "Epoch 9/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0378 - accuracy: 0.9890\n",
      "Epoch 00009: val_accuracy improved from 0.94961 to 0.95007, saving model to VGGModelX3_model_2.h5\n",
      "693/693 [==============================] - 35s 51ms/step - loss: 0.0378 - accuracy: 0.9890 - val_loss: 0.1821 - val_accuracy: 0.9501\n",
      "Epoch 10/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0278 - accuracy: 0.9920\n",
      "Epoch 00010: val_accuracy improved from 0.95007 to 0.96186, saving model to VGGModelX3_model_2.h5\n",
      "693/693 [==============================] - 35s 51ms/step - loss: 0.0278 - accuracy: 0.9920 - val_loss: 0.1489 - val_accuracy: 0.9619\n",
      "Epoch 11/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0223 - accuracy: 0.9948\n",
      "Epoch 00011: val_accuracy did not improve from 0.96186\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0223 - accuracy: 0.9948 - val_loss: 0.1980 - val_accuracy: 0.9547\n",
      "Epoch 12/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0298 - accuracy: 0.9925 ETA: 1s - loss: 0.0\n",
      "Epoch 00012: val_accuracy improved from 0.96186 to 0.96509, saving model to VGGModelX3_model_2.h5\n",
      "693/693 [==============================] - 35s 51ms/step - loss: 0.0298 - accuracy: 0.9925 - val_loss: 0.1466 - val_accuracy: 0.9651\n",
      "Epoch 13/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0216 - accuracy: 0.9940\n",
      "Epoch 00013: val_accuracy improved from 0.96509 to 0.96533, saving model to VGGModelX3_model_2.h5\n",
      "693/693 [==============================] - 35s 51ms/step - loss: 0.0216 - accuracy: 0.9940 - val_loss: 0.1444 - val_accuracy: 0.9653\n",
      "Epoch 14/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0189 - accuracy: 0.9947\n",
      "Epoch 00014: val_accuracy did not improve from 0.96533\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0189 - accuracy: 0.9947 - val_loss: 0.1725 - val_accuracy: 0.9598\n",
      "Epoch 15/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 0.9950\n",
      "Epoch 00015: val_accuracy did not improve from 0.96533\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0175 - accuracy: 0.9950 - val_loss: 0.1682 - val_accuracy: 0.9632\n",
      "Epoch 16/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0226 - accuracy: 0.9938 ETA: 1s - loss:\n",
      "Epoch 00016: val_accuracy did not improve from 0.96533\n",
      "693/693 [==============================] - 34s 50ms/step - loss: 0.0226 - accuracy: 0.9938 - val_loss: 0.1655 - val_accuracy: 0.9642\n",
      "Epoch 17/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0197 - accuracy: 0.9951 ETA: 0s - loss: 0.0201 \n",
      "Epoch 00017: val_accuracy improved from 0.96533 to 0.96718, saving model to VGGModelX3_model_2.h5\n",
      "693/693 [==============================] - 35s 51ms/step - loss: 0.0197 - accuracy: 0.9951 - val_loss: 0.1420 - val_accuracy: 0.9672\n",
      "Epoch 18/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9987 E\n",
      "Epoch 00018: val_accuracy improved from 0.96718 to 0.97041, saving model to VGGModelX3_model_2.h5\n",
      "693/693 [==============================] - 35s 51ms/step - loss: 0.0070 - accuracy: 0.9987 - val_loss: 0.1484 - val_accuracy: 0.9704\n",
      "Epoch 19/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 0.9966\n",
      "Epoch 00019: val_accuracy improved from 0.97041 to 0.97064, saving model to VGGModelX3_model_2.h5\n",
      "693/693 [==============================] - 35s 51ms/step - loss: 0.0118 - accuracy: 0.9966 - val_loss: 0.1556 - val_accuracy: 0.9706\n",
      "Epoch 20/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 0.9981\n",
      "Epoch 00020: val_accuracy did not improve from 0.97064\n",
      "693/693 [==============================] - 34s 50ms/step - loss: 0.0075 - accuracy: 0.9981 - val_loss: 0.1460 - val_accuracy: 0.9697\n",
      "Epoch 21/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 0.9972\n",
      "Epoch 00021: val_accuracy did not improve from 0.97064\n",
      "693/693 [==============================] - 34s 50ms/step - loss: 0.0119 - accuracy: 0.9972 - val_loss: 0.1421 - val_accuracy: 0.9702\n",
      "Epoch 22/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 0.9964\n",
      "Epoch 00022: val_accuracy did not improve from 0.97064\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0134 - accuracy: 0.9964 - val_loss: 0.1553 - val_accuracy: 0.9653\n",
      "Epoch 23/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0144 - accuracy: 0.9961\n",
      "Epoch 00023: val_accuracy did not improve from 0.97064\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0144 - accuracy: 0.9961 - val_loss: 0.1688 - val_accuracy: 0.9637\n",
      "Epoch 24/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 0.9983\n",
      "Epoch 00024: val_accuracy improved from 0.97064 to 0.97203, saving model to VGGModelX3_model_2.h5\n",
      "693/693 [==============================] - 35s 51ms/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 0.1343 - val_accuracy: 0.9720\n",
      "Epoch 25/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9957\n",
      "Epoch 00025: val_accuracy did not improve from 0.97203\n",
      "693/693 [==============================] - 35s 51ms/step - loss: 0.0200 - accuracy: 0.9957 - val_loss: 0.1760 - val_accuracy: 0.9653\n",
      "Epoch 26/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0078 - accuracy: 0.9976\n",
      "Epoch 00026: val_accuracy did not improve from 0.97203\n",
      "693/693 [==============================] - 35s 51ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.1452 - val_accuracy: 0.9690\n",
      "Epoch 27/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9992 ETA: \n",
      "Epoch 00027: val_accuracy did not improve from 0.97203\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.1293 - val_accuracy: 0.9713\n",
      "Epoch 28/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9988\n",
      "Epoch 00028: val_accuracy improved from 0.97203 to 0.97342, saving model to VGGModelX3_model_2.h5\n",
      "693/693 [==============================] - 35s 51ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.1410 - val_accuracy: 0.9734\n",
      "Epoch 29/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0114 - accuracy: 0.9974\n",
      "Epoch 00029: val_accuracy did not improve from 0.97342\n",
      "693/693 [==============================] - 35s 51ms/step - loss: 0.0114 - accuracy: 0.9974 - val_loss: 0.1445 - val_accuracy: 0.9656\n",
      "Epoch 30/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.9986\n",
      "Epoch 00030: val_accuracy did not improve from 0.97342\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0071 - accuracy: 0.9986 - val_loss: 0.1462 - val_accuracy: 0.9644\n",
      "Epoch 31/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.9998\n",
      "Epoch 00031: val_accuracy did not improve from 0.97342\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.1467 - val_accuracy: 0.9690\n",
      "Epoch 32/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9988\n",
      "Epoch 00032: val_accuracy did not improve from 0.97342\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.1551 - val_accuracy: 0.9660\n",
      "Epoch 33/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 0.9949\n",
      "Epoch 00033: val_accuracy did not improve from 0.97342\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0157 - accuracy: 0.9949 - val_loss: 0.1361 - val_accuracy: 0.9699\n",
      "Epoch 34/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.9980\n",
      "Epoch 00034: val_accuracy did not improve from 0.97342\n",
      "693/693 [==============================] - 35s 51ms/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.1342 - val_accuracy: 0.9695\n",
      "Epoch 1/50\n",
      "  1/693 [..............................] - ETA: 0s - loss: 17.0485 - accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0171s vs `on_train_batch_end` time: 0.0281s). Check your callbacks.\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.7689 - accuracy: 0.8038WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0035s vs `on_test_batch_end` time: 0.0100s). Check your callbacks.\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.86936, saving model to VGGModelX3_model_3.h5\n",
      "693/693 [==============================] - 35s 51ms/step - loss: 0.7689 - accuracy: 0.8038 - val_loss: 0.4649 - val_accuracy: 0.8694\n",
      "Epoch 2/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.2976 - accuracy: 0.9189\n",
      "Epoch 00002: val_accuracy improved from 0.86936 to 0.90936, saving model to VGGModelX3_model_3.h5\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.2976 - accuracy: 0.9189 - val_loss: 0.3251 - val_accuracy: 0.9094\n",
      "Epoch 3/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.1785 - accuracy: 0.9487\n",
      "Epoch 00003: val_accuracy improved from 0.90936 to 0.93249, saving model to VGGModelX3_model_3.h5\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.1785 - accuracy: 0.9487 - val_loss: 0.2683 - val_accuracy: 0.9325\n",
      "Epoch 4/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.1202 - accuracy: 0.9657\n",
      "Epoch 00004: val_accuracy did not improve from 0.93249\n",
      "693/693 [==============================] - 34s 50ms/step - loss: 0.1202 - accuracy: 0.9657 - val_loss: 0.2800 - val_accuracy: 0.9228\n",
      "Epoch 5/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0814 - accuracy: 0.9757 ETA: 1s - loss:\n",
      "Epoch 00005: val_accuracy improved from 0.93249 to 0.94358, saving model to VGGModelX3_model_3.h5\n",
      "693/693 [==============================] - 35s 51ms/step - loss: 0.0814 - accuracy: 0.9757 - val_loss: 0.2324 - val_accuracy: 0.9436\n",
      "Epoch 6/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0584 - accuracy: 0.9835\n",
      "Epoch 00006: val_accuracy improved from 0.94358 to 0.94960, saving model to VGGModelX3_model_3.h5\n",
      "693/693 [==============================] - 36s 51ms/step - loss: 0.0584 - accuracy: 0.9835 - val_loss: 0.2138 - val_accuracy: 0.9496\n",
      "Epoch 7/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0535 - accuracy: 0.9846\n",
      "Epoch 00007: val_accuracy did not improve from 0.94960\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0536 - accuracy: 0.9846 - val_loss: 0.2611 - val_accuracy: 0.9413\n",
      "Epoch 8/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0640 - accuracy: 0.9831 ETA: 0s - loss: 0.0649 \n",
      "Epoch 00008: val_accuracy improved from 0.94960 to 0.95422, saving model to VGGModelX3_model_3.h5\n",
      "693/693 [==============================] - 35s 51ms/step - loss: 0.0640 - accuracy: 0.9831 - val_loss: 0.2029 - val_accuracy: 0.9542\n",
      "Epoch 9/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0242 - accuracy: 0.9929\n",
      "Epoch 00009: val_accuracy did not improve from 0.95422\n",
      "693/693 [==============================] - 34s 50ms/step - loss: 0.0242 - accuracy: 0.9929 - val_loss: 0.3128 - val_accuracy: 0.9445\n",
      "Epoch 10/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0287 - accuracy: 0.9921\n",
      "Epoch 00010: val_accuracy did not improve from 0.95422\n",
      "693/693 [==============================] - 34s 50ms/step - loss: 0.0287 - accuracy: 0.9921 - val_loss: 0.2137 - val_accuracy: 0.9535\n",
      "Epoch 11/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 0.9938\n",
      "Epoch 00011: val_accuracy did not improve from 0.95422\n",
      "693/693 [==============================] - 34s 50ms/step - loss: 0.0230 - accuracy: 0.9938 - val_loss: 0.2437 - val_accuracy: 0.9517\n",
      "Epoch 12/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0213 - accuracy: 0.9950\n",
      "Epoch 00012: val_accuracy did not improve from 0.95422\n",
      "693/693 [==============================] - 34s 50ms/step - loss: 0.0213 - accuracy: 0.9950 - val_loss: 0.2640 - val_accuracy: 0.9450\n",
      "Epoch 13/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0220 - accuracy: 0.9939\n",
      "Epoch 00013: val_accuracy improved from 0.95422 to 0.95630, saving model to VGGModelX3_model_3.h5\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0220 - accuracy: 0.9939 - val_loss: 0.2356 - val_accuracy: 0.9563\n",
      "Epoch 14/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0226 - accuracy: 0.9939\n",
      "Epoch 00014: val_accuracy did not improve from 0.95630\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0226 - accuracy: 0.9939 - val_loss: 0.1849 - val_accuracy: 0.9561\n",
      "Epoch 15/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0155 - accuracy: 0.9955\n",
      "Epoch 00015: val_accuracy did not improve from 0.95630\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0155 - accuracy: 0.9955 - val_loss: 0.2097 - val_accuracy: 0.9501\n",
      "Epoch 16/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0122 - accuracy: 0.9969\n",
      "Epoch 00016: val_accuracy improved from 0.95630 to 0.95815, saving model to VGGModelX3_model_3.h5\n",
      "693/693 [==============================] - 35s 51ms/step - loss: 0.0122 - accuracy: 0.9969 - val_loss: 0.2097 - val_accuracy: 0.9582\n",
      "Epoch 17/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 0.9971\n",
      "Epoch 00017: val_accuracy improved from 0.95815 to 0.96023, saving model to VGGModelX3_model_3.h5\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0104 - accuracy: 0.9971 - val_loss: 0.1913 - val_accuracy: 0.9602\n",
      "Epoch 18/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0196 - accuracy: 0.9942\n",
      "Epoch 00018: val_accuracy improved from 0.96023 to 0.96116, saving model to VGGModelX3_model_3.h5\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0196 - accuracy: 0.9942 - val_loss: 0.1818 - val_accuracy: 0.9612\n",
      "Epoch 19/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0098 - accuracy: 0.9975\n",
      "Epoch 00019: val_accuracy improved from 0.96116 to 0.96208, saving model to VGGModelX3_model_3.h5\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0098 - accuracy: 0.9975 - val_loss: 0.2030 - val_accuracy: 0.9621\n",
      "Epoch 20/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 0.9971\n",
      "Epoch 00020: val_accuracy did not improve from 0.96208\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0115 - accuracy: 0.9971 - val_loss: 0.2280 - val_accuracy: 0.9591\n",
      "Epoch 21/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0163 - accuracy: 0.9959\n",
      "Epoch 00021: val_accuracy improved from 0.96208 to 0.96509, saving model to VGGModelX3_model_3.h5\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0163 - accuracy: 0.9959 - val_loss: 0.1863 - val_accuracy: 0.9651\n",
      "Epoch 22/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9994\n",
      "Epoch 00022: val_accuracy did not improve from 0.96509\n",
      "693/693 [==============================] - 34s 50ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.1936 - val_accuracy: 0.9649\n",
      "Epoch 23/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 0.9968\n",
      "Epoch 00023: val_accuracy improved from 0.96509 to 0.96786, saving model to VGGModelX3_model_3.h5\n",
      "693/693 [==============================] - 35s 51ms/step - loss: 0.0125 - accuracy: 0.9968 - val_loss: 0.2066 - val_accuracy: 0.9679\n",
      "Epoch 24/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0091 - accuracy: 0.9974\n",
      "Epoch 00024: val_accuracy did not improve from 0.96786\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0091 - accuracy: 0.9974 - val_loss: 0.2101 - val_accuracy: 0.9639\n",
      "Epoch 25/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9991\n",
      "Epoch 00025: val_accuracy did not improve from 0.96786\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.2191 - val_accuracy: 0.9598\n",
      "Epoch 26/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 0.9985 ETA: 0s - loss: 0.006\n",
      "Epoch 00026: val_accuracy did not improve from 0.96786\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0068 - accuracy: 0.9985 - val_loss: 0.2144 - val_accuracy: 0.9593\n",
      "Epoch 27/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 0.9958\n",
      "Epoch 00027: val_accuracy did not improve from 0.96786\n",
      "693/693 [==============================] - 34s 50ms/step - loss: 0.0147 - accuracy: 0.9958 - val_loss: 0.1691 - val_accuracy: 0.9679\n",
      "Epoch 28/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9994\n",
      "Epoch 00028: val_accuracy did not improve from 0.96786\n",
      "693/693 [==============================] - 34s 50ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.1764 - val_accuracy: 0.9662\n",
      "Epoch 29/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0122 - accuracy: 0.9971\n",
      "Epoch 00029: val_accuracy improved from 0.96786 to 0.97133, saving model to VGGModelX3_model_3.h5\n",
      "693/693 [==============================] - 36s 51ms/step - loss: 0.0122 - accuracy: 0.9971 - val_loss: 0.1905 - val_accuracy: 0.9713\n",
      "Epoch 30/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 0.9965\n",
      "Epoch 00030: val_accuracy did not improve from 0.97133\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0155 - accuracy: 0.9965 - val_loss: 0.2225 - val_accuracy: 0.9639\n",
      "Epoch 31/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9986\n",
      "Epoch 00031: val_accuracy did not improve from 0.97133\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.1806 - val_accuracy: 0.9672\n",
      "Epoch 32/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.9990\n",
      "Epoch 00032: val_accuracy did not improve from 0.97133\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0052 - accuracy: 0.9990 - val_loss: 0.1812 - val_accuracy: 0.9688\n",
      "Epoch 33/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9984\n",
      "Epoch 00033: val_accuracy did not improve from 0.97133\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 0.1813 - val_accuracy: 0.9665\n",
      "Epoch 34/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9986\n",
      "Epoch 00034: val_accuracy did not improve from 0.97133\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 0.2070 - val_accuracy: 0.9702\n",
      "Epoch 35/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0142 - accuracy: 0.9966\n",
      "Epoch 00035: val_accuracy did not improve from 0.97133\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0142 - accuracy: 0.9966 - val_loss: 0.1723 - val_accuracy: 0.9688\n",
      "Epoch 1/50\n",
      "  1/693 [..............................] - ETA: 0s - loss: 15.7458 - accuracy: 0.0400WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0176s vs `on_train_batch_end` time: 0.0291s). Check your callbacks.\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.7700 - accuracy: 0.8042WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0030s vs `on_test_batch_end` time: 0.0111s). Check your callbacks.\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.88855, saving model to VGGModelX3_model_4.h5\n",
      "693/693 [==============================] - 36s 51ms/step - loss: 0.7699 - accuracy: 0.8042 - val_loss: 0.3877 - val_accuracy: 0.8886\n",
      "Epoch 2/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.3031 - accuracy: 0.9153\n",
      "Epoch 00002: val_accuracy improved from 0.88855 to 0.93457, saving model to VGGModelX3_model_4.h5\n",
      "693/693 [==============================] - 35s 51ms/step - loss: 0.3031 - accuracy: 0.9153 - val_loss: 0.2369 - val_accuracy: 0.9346\n",
      "Epoch 3/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.1832 - accuracy: 0.9483\n",
      "Epoch 00003: val_accuracy did not improve from 0.93457\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.1832 - accuracy: 0.9483 - val_loss: 0.2212 - val_accuracy: 0.9336\n",
      "Epoch 4/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.1216 - accuracy: 0.9641\n",
      "Epoch 00004: val_accuracy improved from 0.93457 to 0.94913, saving model to VGGModelX3_model_4.h5\n",
      "693/693 [==============================] - 35s 51ms/step - loss: 0.1216 - accuracy: 0.9641 - val_loss: 0.1954 - val_accuracy: 0.9491\n",
      "Epoch 5/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0907 - accuracy: 0.9740\n",
      "Epoch 00005: val_accuracy improved from 0.94913 to 0.95121, saving model to VGGModelX3_model_4.h5\n",
      "693/693 [==============================] - 35s 51ms/step - loss: 0.0907 - accuracy: 0.9740 - val_loss: 0.1796 - val_accuracy: 0.9512\n",
      "Epoch 6/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0697 - accuracy: 0.9796\n",
      "Epoch 00006: val_accuracy improved from 0.95121 to 0.96116, saving model to VGGModelX3_model_4.h5\n",
      "693/693 [==============================] - 35s 51ms/step - loss: 0.0697 - accuracy: 0.9795 - val_loss: 0.1584 - val_accuracy: 0.9612\n",
      "Epoch 7/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0693 - accuracy: 0.9807\n",
      "Epoch 00007: val_accuracy did not improve from 0.96116\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0693 - accuracy: 0.9807 - val_loss: 0.1508 - val_accuracy: 0.9609\n",
      "Epoch 8/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0433 - accuracy: 0.9871\n",
      "Epoch 00008: val_accuracy improved from 0.96116 to 0.96717, saving model to VGGModelX3_model_4.h5\n",
      "693/693 [==============================] - 35s 51ms/step - loss: 0.0433 - accuracy: 0.9871 - val_loss: 0.1345 - val_accuracy: 0.9672\n",
      "Epoch 9/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0375 - accuracy: 0.9887 ETA: 2s - loss: 0 - ETA: 0s - loss: 0.037\n",
      "Epoch 00009: val_accuracy did not improve from 0.96717\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0375 - accuracy: 0.9887 - val_loss: 0.1539 - val_accuracy: 0.9598\n",
      "Epoch 10/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0265 - accuracy: 0.9931\n",
      "Epoch 00010: val_accuracy did not improve from 0.96717\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0265 - accuracy: 0.9931 - val_loss: 0.1680 - val_accuracy: 0.9637\n",
      "Epoch 11/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0298 - accuracy: 0.9921\n",
      "Epoch 00011: val_accuracy improved from 0.96717 to 0.96925, saving model to VGGModelX3_model_4.h5\n",
      "693/693 [==============================] - 35s 51ms/step - loss: 0.0298 - accuracy: 0.9921 - val_loss: 0.1478 - val_accuracy: 0.9692\n",
      "Epoch 12/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 0.9930\n",
      "Epoch 00012: val_accuracy did not improve from 0.96925\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0246 - accuracy: 0.9930 - val_loss: 0.1323 - val_accuracy: 0.9686\n",
      "Epoch 13/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0187 - accuracy: 0.9954\n",
      "Epoch 00013: val_accuracy did not improve from 0.96925\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0187 - accuracy: 0.9954 - val_loss: 0.1815 - val_accuracy: 0.9582\n",
      "Epoch 14/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0261 - accuracy: 0.9925\n",
      "Epoch 00014: val_accuracy did not improve from 0.96925\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0261 - accuracy: 0.9925 - val_loss: 0.1479 - val_accuracy: 0.9662\n",
      "Epoch 15/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0129 - accuracy: 0.9968\n",
      "Epoch 00015: val_accuracy did not improve from 0.96925\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0129 - accuracy: 0.9968 - val_loss: 0.1627 - val_accuracy: 0.9686\n",
      "Epoch 16/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0181 - accuracy: 0.9948\n",
      "Epoch 00016: val_accuracy did not improve from 0.96925\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0180 - accuracy: 0.9948 - val_loss: 0.1550 - val_accuracy: 0.9614\n",
      "Epoch 17/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0216 - accuracy: 0.9950\n",
      "Epoch 00017: val_accuracy improved from 0.96925 to 0.97040, saving model to VGGModelX3_model_4.h5\n",
      "693/693 [==============================] - 35s 51ms/step - loss: 0.0216 - accuracy: 0.9950 - val_loss: 0.1159 - val_accuracy: 0.9704\n",
      "Epoch 18/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0152 - accuracy: 0.9962\n",
      "Epoch 00018: val_accuracy improved from 0.97040 to 0.97272, saving model to VGGModelX3_model_4.h5\n",
      "693/693 [==============================] - 35s 51ms/step - loss: 0.0152 - accuracy: 0.9962 - val_loss: 0.1113 - val_accuracy: 0.9727\n",
      "Epoch 19/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9974\n",
      "Epoch 00019: val_accuracy did not improve from 0.97272\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0093 - accuracy: 0.9974 - val_loss: 0.1483 - val_accuracy: 0.9651\n",
      "Epoch 20/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0079 - accuracy: 0.9981\n",
      "Epoch 00020: val_accuracy improved from 0.97272 to 0.97364, saving model to VGGModelX3_model_4.h5\n",
      "693/693 [==============================] - 35s 51ms/step - loss: 0.0079 - accuracy: 0.9981 - val_loss: 0.1468 - val_accuracy: 0.9736\n",
      "Epoch 21/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0255 - accuracy: 0.9933\n",
      "Epoch 00021: val_accuracy improved from 0.97364 to 0.97387, saving model to VGGModelX3_model_4.h5\n",
      "693/693 [==============================] - 35s 51ms/step - loss: 0.0255 - accuracy: 0.9933 - val_loss: 0.1341 - val_accuracy: 0.9739\n",
      "Epoch 22/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9993\n",
      "Epoch 00022: val_accuracy did not improve from 0.97387\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.1427 - val_accuracy: 0.9704\n",
      "Epoch 23/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9995\n",
      "Epoch 00023: val_accuracy improved from 0.97387 to 0.97595, saving model to VGGModelX3_model_4.h5\n",
      "693/693 [==============================] - 35s 51ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.1270 - val_accuracy: 0.9760\n",
      "Epoch 24/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0089 - accuracy: 0.9975 ETA: 1s - los\n",
      "Epoch 00024: val_accuracy did not improve from 0.97595\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0089 - accuracy: 0.9975 - val_loss: 0.1406 - val_accuracy: 0.9695\n",
      "Epoch 25/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 0.9957\n",
      "Epoch 00025: val_accuracy improved from 0.97595 to 0.97780, saving model to VGGModelX3_model_4.h5\n",
      "693/693 [==============================] - 35s 51ms/step - loss: 0.0163 - accuracy: 0.9957 - val_loss: 0.1180 - val_accuracy: 0.9778\n",
      "Epoch 26/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9985\n",
      "Epoch 00026: val_accuracy did not improve from 0.97780\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.1671 - val_accuracy: 0.9651\n",
      "Epoch 27/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9983\n",
      "Epoch 00027: val_accuracy did not improve from 0.97780\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.1331 - val_accuracy: 0.9716\n",
      "Epoch 28/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0128 - accuracy: 0.9969\n",
      "Epoch 00028: val_accuracy did not improve from 0.97780\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0128 - accuracy: 0.9969 - val_loss: 0.1466 - val_accuracy: 0.9750\n",
      "Epoch 29/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9973\n",
      "Epoch 00029: val_accuracy did not improve from 0.97780\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 0.1216 - val_accuracy: 0.9723\n",
      "Epoch 30/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.9972\n",
      "Epoch 00030: val_accuracy did not improve from 0.97780\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0098 - accuracy: 0.9972 - val_loss: 0.1498 - val_accuracy: 0.9709\n",
      "Epoch 31/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9990\n",
      "Epoch 00031: val_accuracy did not improve from 0.97780\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.1169 - val_accuracy: 0.9764\n",
      "Epoch 1/50\n",
      "  1/693 [..............................] - ETA: 0s - loss: 21.1655 - accuracy: 0.0400WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0171s vs `on_train_batch_end` time: 0.0281s). Check your callbacks.\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.8184 - accuracy: 0.7989WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_test_batch_end` time: 0.0111s). Check your callbacks.\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.89757, saving model to VGGModelX3_model_5.h5\n",
      "693/693 [==============================] - 35s 51ms/step - loss: 0.8184 - accuracy: 0.7989 - val_loss: 0.3961 - val_accuracy: 0.8976\n",
      "Epoch 2/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.3005 - accuracy: 0.9163\n",
      "Epoch 00002: val_accuracy improved from 0.89757 to 0.90173, saving model to VGGModelX3_model_5.h5\n",
      "693/693 [==============================] - 35s 51ms/step - loss: 0.3005 - accuracy: 0.9163 - val_loss: 0.3600 - val_accuracy: 0.9017\n",
      "Epoch 3/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.1846 - accuracy: 0.9478\n",
      "Epoch 00003: val_accuracy improved from 0.90173 to 0.93549, saving model to VGGModelX3_model_5.h5\n",
      "693/693 [==============================] - 35s 51ms/step - loss: 0.1846 - accuracy: 0.9478 - val_loss: 0.2309 - val_accuracy: 0.9355\n",
      "Epoch 4/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.1155 - accuracy: 0.9666 ETA: 0s - loss: 0.1159 - ac\n",
      "Epoch 00004: val_accuracy improved from 0.93549 to 0.94058, saving model to VGGModelX3_model_5.h5\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.1160 - accuracy: 0.9666 - val_loss: 0.2219 - val_accuracy: 0.9406\n",
      "Epoch 5/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0877 - accuracy: 0.9744\n",
      "Epoch 00005: val_accuracy improved from 0.94058 to 0.95052, saving model to VGGModelX3_model_5.h5\n",
      "693/693 [==============================] - 35s 51ms/step - loss: 0.0877 - accuracy: 0.9744 - val_loss: 0.2099 - val_accuracy: 0.9505\n",
      "Epoch 6/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0572 - accuracy: 0.9846\n",
      "Epoch 00006: val_accuracy did not improve from 0.95052\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0572 - accuracy: 0.9846 - val_loss: 0.2335 - val_accuracy: 0.9436\n",
      "Epoch 7/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0482 - accuracy: 0.9859\n",
      "Epoch 00007: val_accuracy did not improve from 0.95052\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0482 - accuracy: 0.9859 - val_loss: 0.2848 - val_accuracy: 0.9334\n",
      "Epoch 8/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0422 - accuracy: 0.9888\n",
      "Epoch 00008: val_accuracy did not improve from 0.95052\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0422 - accuracy: 0.9888 - val_loss: 0.2263 - val_accuracy: 0.9489\n",
      "Epoch 9/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0324 - accuracy: 0.9909\n",
      "Epoch 00009: val_accuracy improved from 0.95052 to 0.95237, saving model to VGGModelX3_model_5.h5\n",
      "693/693 [==============================] - 35s 51ms/step - loss: 0.0324 - accuracy: 0.9909 - val_loss: 0.2052 - val_accuracy: 0.9524\n",
      "Epoch 10/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0279 - accuracy: 0.9923\n",
      "Epoch 00010: val_accuracy did not improve from 0.95237\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0279 - accuracy: 0.9923 - val_loss: 0.2114 - val_accuracy: 0.9431\n",
      "Epoch 11/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0262 - accuracy: 0.9922\n",
      "Epoch 00011: val_accuracy improved from 0.95237 to 0.95746, saving model to VGGModelX3_model_5.h5\n",
      "693/693 [==============================] - 35s 51ms/step - loss: 0.0262 - accuracy: 0.9922 - val_loss: 0.1973 - val_accuracy: 0.9575\n",
      "Epoch 12/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0182 - accuracy: 0.9957\n",
      "Epoch 00012: val_accuracy improved from 0.95746 to 0.96000, saving model to VGGModelX3_model_5.h5\n",
      "693/693 [==============================] - 35s 51ms/step - loss: 0.0182 - accuracy: 0.9957 - val_loss: 0.2155 - val_accuracy: 0.9600\n",
      "Epoch 13/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0223 - accuracy: 0.9946\n",
      "Epoch 00013: val_accuracy improved from 0.96000 to 0.96370, saving model to VGGModelX3_model_5.h5\n",
      "693/693 [==============================] - 35s 51ms/step - loss: 0.0223 - accuracy: 0.9946 - val_loss: 0.1756 - val_accuracy: 0.9637\n",
      "Epoch 14/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0173 - accuracy: 0.9951\n",
      "Epoch 00014: val_accuracy improved from 0.96370 to 0.96509, saving model to VGGModelX3_model_5.h5\n",
      "693/693 [==============================] - 35s 51ms/step - loss: 0.0172 - accuracy: 0.9951 - val_loss: 0.1736 - val_accuracy: 0.9651\n",
      "Epoch 15/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0165 - accuracy: 0.9957\n",
      "Epoch 00015: val_accuracy did not improve from 0.96509\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0165 - accuracy: 0.9957 - val_loss: 0.2292 - val_accuracy: 0.9565\n",
      "Epoch 16/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0184 - accuracy: 0.9955\n",
      "Epoch 00016: val_accuracy improved from 0.96509 to 0.96717, saving model to VGGModelX3_model_5.h5\n",
      "693/693 [==============================] - 35s 51ms/step - loss: 0.0184 - accuracy: 0.9955 - val_loss: 0.1501 - val_accuracy: 0.9672\n",
      "Epoch 17/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0138 - accuracy: 0.9967\n",
      "Epoch 00017: val_accuracy did not improve from 0.96717\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0138 - accuracy: 0.9967 - val_loss: 0.1801 - val_accuracy: 0.9646\n",
      "Epoch 18/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9994\n",
      "Epoch 00018: val_accuracy did not improve from 0.96717\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.2197 - val_accuracy: 0.9639\n",
      "Epoch 19/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 0.9967\n",
      "Epoch 00019: val_accuracy did not improve from 0.96717\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0134 - accuracy: 0.9967 - val_loss: 0.2038 - val_accuracy: 0.9612\n",
      "Epoch 20/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0184 - accuracy: 0.9958\n",
      "Epoch 00020: val_accuracy improved from 0.96717 to 0.96994, saving model to VGGModelX3_model_5.h5\n",
      "693/693 [==============================] - 35s 51ms/step - loss: 0.0184 - accuracy: 0.9958 - val_loss: 0.1793 - val_accuracy: 0.9699\n",
      "Epoch 21/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 0.9981\n",
      "Epoch 00021: val_accuracy did not improve from 0.96994\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0065 - accuracy: 0.9981 - val_loss: 0.1846 - val_accuracy: 0.9625\n",
      "Epoch 22/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 0.9976\n",
      "Epoch 00022: val_accuracy did not improve from 0.96994\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 0.2335 - val_accuracy: 0.9662\n",
      "Epoch 23/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9988 E\n",
      "Epoch 00023: val_accuracy did not improve from 0.96994\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.2355 - val_accuracy: 0.9524\n",
      "Epoch 24/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0166 - accuracy: 0.9954\n",
      "Epoch 00024: val_accuracy improved from 0.96994 to 0.97156, saving model to VGGModelX3_model_5.h5\n",
      "693/693 [==============================] - 35s 51ms/step - loss: 0.0166 - accuracy: 0.9954 - val_loss: 0.1970 - val_accuracy: 0.9716\n",
      "Epoch 25/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9984\n",
      "Epoch 00025: val_accuracy did not improve from 0.97156\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.2082 - val_accuracy: 0.9628\n",
      "Epoch 26/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0088 - accuracy: 0.9979\n",
      "Epoch 00026: val_accuracy did not improve from 0.97156\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0088 - accuracy: 0.9979 - val_loss: 0.2295 - val_accuracy: 0.9688\n",
      "Epoch 27/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9975\n",
      "Epoch 00027: val_accuracy did not improve from 0.97156\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0090 - accuracy: 0.9975 - val_loss: 0.2128 - val_accuracy: 0.9709\n",
      "Epoch 28/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995\n",
      "Epoch 00028: val_accuracy did not improve from 0.97156\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.2621 - val_accuracy: 0.9704\n",
      "Epoch 29/50\n",
      "693/693 [==============================] - ETA: 0s - loss: 1.3064e-04 - accuracy: 1.0000\n",
      "Epoch 00029: val_accuracy did not improve from 0.97156\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 1.3064e-04 - accuracy: 1.0000 - val_loss: 0.2867 - val_accuracy: 0.9706\n",
      "Epoch 30/50\n",
      "692/693 [============================>.] - ETA: 0s - loss: 1.4418e-04 - accuracy: 0.9999\n",
      "Epoch 00030: val_accuracy did not improve from 0.97156\n",
      "693/693 [==============================] - 35s 50ms/step - loss: 1.4416e-04 - accuracy: 0.9999 - val_loss: 0.3018 - val_accuracy: 0.9672\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=5, random_state=6, shuffle=True)\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(np.array(y_image).reshape(-1, 1))\n",
    "fold_var =1\n",
    "tfidfX = tf_idf_dataframe\n",
    "genderenc = OneHotEncoder(handle_unknown='ignore')\n",
    "genderenc = genderenc.fit(np.array(df[\"gender\"]).reshape(-1, 1))\n",
    "gender_oneHot =genderenc.transform(np.array(df[\"gender\"]).reshape(-1, 1)).toarray()\n",
    "\n",
    "\n",
    "baseColourenc = OneHotEncoder(handle_unknown='ignore')\n",
    "baseColourenc = baseColourenc.fit(np.array(df[\"baseColour\"]).reshape(-1, 1))\n",
    "baseCol_oneHot = baseColourenc.transform(np.array(df[\"baseColour\"]).reshape(-1, 1)).toarray()\n",
    "\n",
    "seasonenc = OneHotEncoder(handle_unknown='ignore')\n",
    "seasonenc = seasonenc.fit(np.array(df[\"season\"]).reshape(-1, 1))\n",
    "season_oneHot = seasonenc.transform(np.array(df[\"season\"]).reshape(-1, 1)).toarray()\n",
    "\n",
    "usageenc = OneHotEncoder(handle_unknown='ignore')\n",
    "usageenc = usageenc.fit(np.array(df[\"usage\"]).reshape(-1, 1))\n",
    "usage_oneHot = usageenc.transform(np.array(df[\"usage\"]).reshape(-1, 1)).toarray()\n",
    "tfidfX = tf_idf_dataframe\n",
    "tfidfX = np.hstack((np.array(tfidfX),gender_oneHot,baseCol_oneHot,\n",
    "                season_oneHot,usage_oneHot))\n",
    "\n",
    "\n",
    "\n",
    "def create_new_modelVGGX_TFIDF() :\n",
    "    inputA = tf.keras.Input(shape=(60, 60, 3))\n",
    "    inputB = tf.keras.Input(shape=(tfidfX.shape[1],))\n",
    "    vgg_model = VGG16(weights='imagenet',include_top=False,input_shape=(60, 60, 3))#(inputA) #, \n",
    "    # Freeze four convolution blocks\n",
    "    for layer in vgg_model.layers[:15]:\n",
    "#         layer.trainable = False# Make sure you have frozen the correct layers\n",
    "        layer.trainable = True\n",
    "    for layer in vgg_model.layers[15:]:\n",
    "        layer.trainable = True\n",
    "#     for i, layer in enumerate(vgg_model.layers):\n",
    "#         print(i, layer.name, layer.trainable)\n",
    "#     x = vgg_model(inputA).output\n",
    "    x = vgg_model.output\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    y = tf.keras.layers.Dense(1024, activation=\"relu\")(inputB)\n",
    "    y = tf.keras.Model(inputs=inputB, outputs=y)\n",
    "    \n",
    "    combined = keras.layers.concatenate([x, y.output])\n",
    "    \n",
    "    z = tf.keras.layers.Flatten()(combined) # Flatten dimensions to for use in FC layers\n",
    "#     z = tf.keras.layers.Dense(256, activation='relu')(z)\n",
    "#     z = tf.keras.layers.Dropout(0.2)(z) # Dropout layer to reduce overfitting\n",
    "    z = tf.keras.layers.Dense(256, activation='relu')(z)\n",
    "    z = tf.keras.layers.Dense(27, activation='softmax')(z) # Softmax for multiclass\n",
    "    transfer_model = tf.keras.Model(inputs=[vgg_model.input,y.input], outputs=z)\n",
    "    \n",
    "    return transfer_model\n",
    "\n",
    "for train, test in kfold.split(imageX, tfidfX, y_image ):\n",
    "    trainImageX, valImageX = imageX[train], imageX[test]\n",
    "    traintfidfX, valtfidfX = tfidfX[train], tfidfX[test]\n",
    "    trainY, valY = y_image[train], y_image[test]\n",
    "    trainY_oneHot = enc.transform(np.array(trainY).reshape(-1, 1)).toarray()\n",
    "    valY_oneHot = enc.transform(np.array(valY).reshape(-1, 1)).toarray()\n",
    "    #transfer_model.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(lr=5e-5), metrics=[\"accuracy\"])\n",
    "\n",
    "   # history = transfer_model.fit(imageX, y_onehot, batch_size = 128, epochs=20)\n",
    "    \n",
    "    model2 = create_new_modelVGGX_TFIDF()\n",
    "    # COMPILE NEW MODEL\n",
    "    model2.compile(loss='categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=5e-5),\n",
    "    metrics=['accuracy'])\n",
    "    earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=6)\n",
    "#     checkpoint = tf.keras.callbacks.ModelCheckpoint(\"VGGModelX_\"+get_model_name(fold_var), \n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"VGGModelX3_\"+get_model_name(fold_var), \n",
    "                            monitor='val_accuracy', verbose=1, \n",
    "                            save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint,earlystop]\n",
    "    \n",
    "    history = model2.fit(x=[trainImageX, traintfidfX], y= trainY_oneHot, epochs=50, batch_size = 25,\n",
    "                        callbacks=callbacks_list,validation_data= ([valImageX, valtfidfX], valY_oneHot ))\n",
    "    #saved_model = load_model('best_model.h5')\n",
    "    #print('Model evaluation ',model2.evaluate(valX , valY_oneHot))\n",
    "    #model.fit(trainX, trainY,epochs=20)\n",
    "    \n",
    "    fold_var += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the K fold's looking for best validation accuracy, in this case it is VGGModelX3_model_4.h5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_features=1000, smooth_idf=False, stop_words='english')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fittedTFIDFVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Import test.csv and do sample data processing so we can use the best model prediction to make our prediction CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>baseColour</th>\n",
       "      <th>season</th>\n",
       "      <th>usage</th>\n",
       "      <th>noisyTextDescription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26266</td>\n",
       "      <td>Men</td>\n",
       "      <td>Black</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Chromozome Men Black Fashion Vest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22134</td>\n",
       "      <td>Women</td>\n",
       "      <td>Green</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Elle Women Green Color Clash Top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28358</td>\n",
       "      <td>Women</td>\n",
       "      <td>Black</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Baggit Women Chotu Mayur Black Palms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15554</td>\n",
       "      <td>Men</td>\n",
       "      <td>Black</td>\n",
       "      <td>Fall</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Greensboro Colors Of Ap Men Latnam Black Casua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53408</td>\n",
       "      <td>Women</td>\n",
       "      <td>Purple</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Fish White Smooth daddy (SH100)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id gender baseColour  season   usage  \\\n",
       "0  26266    Men      Black  Summer  Casual   \n",
       "1  22134  Women      Green  Summer  Casual   \n",
       "2  28358  Women      Black  Winter  Casual   \n",
       "3  15554    Men      Black    Fall  Casual   \n",
       "4  53408  Women     Purple  Summer  Casual   \n",
       "\n",
       "                                noisyTextDescription  \n",
       "0                  Chromozome Men Black Fashion Vest  \n",
       "1                   Elle Women Green Color Clash Top  \n",
       "2               Baggit Women Chotu Mayur Black Palms  \n",
       "3  Greensboro Colors Of Ap Men Latnam Black Casua...  \n",
       "4                    Fish White Smooth daddy (SH100)  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTest = pd.read_csv ('test.csv')\n",
    "# dfTest = pd.read_csv ('train.csv')\n",
    "dfTest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21628, 1000)\n"
     ]
    }
   ],
   "source": [
    "#Test data transformation\n",
    "\n",
    "#clean text\n",
    "dfTest['clean'] = dfTest['noisyTextDescription'].apply(lambda x: process_text(str(x)))\n",
    "tf_idf_Testdata =  fittedTFIDFVectorizer.transform(dfTest['clean'])\n",
    "#tf_idf_Testdata =  fittedTFIDFVectorizer.transform(dfTest['clean'])\n",
    "tf_idf_Testdata=pd.DataFrame(tf_idf_Testdata.toarray(),columns=fittedTFIDFVectorizer.get_feature_names())\n",
    "print (tf_idf_Testdata.shape)\n",
    "\n",
    "# genderenc = OneHotEncoder(handle_unknown='ignore')\n",
    "# genderenc = genderenc.fit(np.array(df[\"gender\"]).reshape(-1, 1))\n",
    "gender_oneHotTest =genderenc.transform(np.array(dfTest[\"gender\"]).reshape(-1, 1)).toarray()\n",
    "\n",
    "\n",
    "# baseColourenc = OneHotEncoder(handle_unknown='ignore')\n",
    "# baseColourenc = baseColourenc.fit(np.array(df[\"baseColour\"]).reshape(-1, 1))\n",
    "baseCol_oneHotTest = baseColourenc.transform(np.array(dfTest[\"baseColour\"]).reshape(-1, 1)).toarray()\n",
    "\n",
    "# seasonenc = OneHotEncoder(handle_unknown='ignore')\n",
    "# seasonenc = seasonenc.fit(np.array(df[\"season\"]).reshape(-1, 1))\n",
    "season_oneHotTest = seasonenc.transform(np.array(dfTest[\"season\"]).reshape(-1, 1)).toarray()\n",
    "\n",
    "# usageenc = OneHotEncoder(handle_unknown='ignore')\n",
    "# usageenc = usageenc.fit(np.array(df[\"usage\"]).reshape(-1, 1))\n",
    "usage_oneHotTest = usageenc.transform(np.array(dfTest[\"usage\"]).reshape(-1, 1)).toarray()\n",
    "# tfidfX = tf_idf_dataframe\n",
    "tfidfX_TEST = np.hstack((np.array(tf_idf_Testdata),gender_oneHotTest,baseCol_oneHotTest,\n",
    "                season_oneHotTest,usage_oneHotTest))\n",
    "\n",
    "# imageX for test data\n",
    "\n",
    "imageX_test = GetImageDS(dfTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21628, 1000)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_Testdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saved2_model = load_model('VGGModelX_model_1.h5')\n",
    "saved2_model = load_model('VGGModelX3_model_4.h5')\n",
    "\n",
    "\n",
    "saved2_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "# print('Model evaluation ',saved_model.evaluate([imageX_test,tfidfX_TEST] , Y_testOneHot))\n",
    "result = saved2_model.predict([imageX_test,tfidfX_TEST])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21628, 27)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26266</td>\n",
       "      <td>Innerwear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22134</td>\n",
       "      <td>Topwear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28358</td>\n",
       "      <td>Belts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15554</td>\n",
       "      <td>Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53408</td>\n",
       "      <td>Innerwear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id   category\n",
       "0  26266  Innerwear\n",
       "1  22134    Topwear\n",
       "2  28358      Belts\n",
       "3  15554      Shoes\n",
       "4  53408  Innerwear"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_array = enc.inverse_transform(tf.one_hot(tf.argmax(result, axis=1), depth = 27))\n",
    "np.transpose(np.array((dfTest[\"id\"],predict_array[:,0])))\n",
    "saveFrame  = pd.DataFrame(data=np.transpose(np.array((dfTest[\"id\"],predict_array[:,0]))), columns=['id', 'category'])\n",
    "saveFrame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will export the dataset as a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveFrame.to_csv('submission7_03_12.csv', header=True, index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
